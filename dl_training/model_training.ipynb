{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text classification using BERT pre-trained models\n",
    "The current code was adapted from this TF website: https://www.tensorflow.org/text/tutorials/classify_text_with_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow\n",
    "!pip install -q -U tensorflow-text\n",
    "!pip install -q tf-models-official"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "from official.nlp import optimization  # to create AdamW optimizer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load dataset from JSON file\n",
    "data_inputs = []\n",
    "data_labels = []\n",
    "with open(\"dataset/News_Category_Dataset_v2.json\", \"r\") as f:\n",
    "    for line in f:\n",
    "        article = json.loads(line)\n",
    "        data_inputs.append(article[\"headline\"])\n",
    "        data_labels.append(article[\"category\"])\n",
    "\n",
    "all_labels = np.array(list(set(all_labels)))\n",
    "num_topics = all_labels.shape[0]\n",
    "data_inputs = np.array(data_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "\n",
    "#Create one-hot encoding for the labels\n",
    "#1. Encode each label (topic) into num type\n",
    "#Label_encoder object knows how to understand word labels\n",
    "label_encoder = LabelEncoder()\n",
    "#Encode labels\n",
    "numeric_labels = label_encoder.fit_transform(data_labels)\n",
    "\n",
    "#2. Get one-hot encoding of each label\n",
    "onehotencoder = OneHotEncoder()\n",
    "#Reshape the 1-D label array to 2-D, as fit_transform expects 2-D, and fit the array \n",
    "numeric_labels = onehotencoder.fit_transform(numeric_labels.reshape(-1,1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split dataset to get train, test and validation splits (80-10-10)\n",
    "x_train, x_test, y_train, y_test = train_test_split(data_inputs, numeric_labels, test_size=0.1, random_state=1)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.111, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select BERT model to use and fine-tune\n",
    "tfhub_handle_encoder = \"https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\"\n",
    "tfhub_handle_preprocess = \"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dropout, Dense\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "#Load pre-processing model and main BERT model as Keras Layers\n",
    "bert_preprocess_layer = hub.KerasLayer(tfhub_handle_preprocess, name=\"preprocessing\")\n",
    "bert_encoder_layer = hub.KerasLayer(tfhub_handle_encoder, trainable=True, name=\"BERT_encoder\")\n",
    "#Create classifier model to fine-tune BERT outputs\n",
    "def build_classifier_model():\n",
    "    text_input = Input(shape=(), dtype=tf.string, name='text')\n",
    "    encoder_inputs = bert_preprocess_model(text_input)\n",
    "    outputs = bert_encoder_layer(encoder_inputs)\n",
    "    net = outputs['pooled_output']\n",
    "    net = Dropout(0.1)(net)\n",
    "    net = Dense(num_topics, activation=None, name='classifier')(net)\n",
    "    return Model(text_input, net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "\n",
    "#Define loss function\n",
    "loss = CategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "#Define epochs and optimizer as AdamW\n",
    "epochs = 5\n",
    "steps_per_epoch = len(x_train)\n",
    "num_train_steps = steps_per_epoch * epochs\n",
    "num_warmup_steps = int(0.1*num_train_steps)\n",
    "\n",
    "init_lr = 3e-5\n",
    "optimizer = optimization.create_optimizer(init_lr=init_lr,\n",
    "                                          num_train_steps=num_train_steps,\n",
    "                                          num_warmup_steps=num_warmup_steps,\n",
    "                                          optimizer_type='adamw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build and compile model with given loss and metrics needed\n",
    "classifier_model = build_classifier_model()\n",
    "classifier_model.compile(optimizer=optimizer,\n",
    "                         loss=loss,\n",
    "                         metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit model\n",
    "history = classifier_model.fit(x=x_train, y=y_train,\n",
    "                               validation_data=(x_val, y_val), \n",
    "                               epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
